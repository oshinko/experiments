{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8c9b6a",
   "metadata": {},
   "source": [
    "# rinna/japanese-gpt 実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3286777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 20 12:23:52 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 532.03                 Driver Version: 532.03       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1080 Ti    WDDM | 00000000:2E:00.0  On |                  N/A |\n",
      "| 31%   61C    P0              110W / 352W|   1068MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "def show_gpus():\n",
    "    lines = !nvidia-smi\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            break\n",
    "\n",
    "        print(line)\n",
    "\n",
    "show_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd1f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except ModuleNotFoundError as e:\n",
    "    raise ModuleNotFoundError('Install PyTorch from https://pytorch.org/.') from e\n",
    "\n",
    "try:\n",
    "    import accelerate, sentencepiece, transformers\n",
    "except ModuleNotFoundError:\n",
    "    !{sys.executable} -m pip install accelerate sentencepiece transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524609e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "pretrained_model_name_or_path = 'rinna/japanese-gpt-neox-3.6b-instruction-ppo'\n",
    "# pretrained_model_name_or_path = 'rinna/japanese-gpt-1b'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    torch_dtype=torch.float16,  # VRAM に余裕があるなら None or torch.float32 でイイ\n",
    "    device_map='auto'\n",
    ")\n",
    "model.tie_weights()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87079284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 20 12:24:13 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 532.03                 Driver Version: 532.03       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1080 Ti    WDDM | 00000000:2E:00.0  On |                  N/A |\n",
      "| 31%   61C    P0              109W / 352W|   8740MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "show_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3334b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(messages, leading=''):\n",
    "    prompt = [\n",
    "        uttr['speaker'] + ': ' + uttr['text'].replace('\\n', '<NL>')\n",
    "        for uttr in messages\n",
    "    ]\n",
    "\n",
    "    prompt = '<NL>'.join(prompt)\n",
    "\n",
    "    prompt = (\n",
    "        prompt\n",
    "        + '<NL>'\n",
    "        + 'システム: '\n",
    "        + leading\n",
    "    )\n",
    "\n",
    "    print(prompt.replace('<NL>', '\\n'), end='')\n",
    "\n",
    "    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            token_ids.to(model.device),\n",
    "            do_sample=True,\n",
    "            max_new_tokens=128,\n",
    "            temperature=0.7,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    output = tokenizer.decode(output_ids.tolist()[0][token_ids.size(1):])\n",
    "    output = output.replace('<NL>', '\\n').replace('</s>', '')\n",
    "\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f0479b",
   "metadata": {},
   "source": [
    "## 天気予報を聞く\n",
    "\n",
    "- ハルシネーションが発生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7851092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ユーザー: こんにちは！あなたは今日の天気予報をご存知ですか？\n",
      "システム: もちろんです。今日の東京の天気は、晴れ時々曇りで、最高気温は27度になる予報です。また、湿度も高いです。明日は、一日中雨が降り、最高気温は23度になる予報です。全体的に、東京は非常に良い天気で、過ごしやすいです。今日と明日は外出する予定があれば、傘を持って行った方が良いかもしれません。また、運動や散歩などの屋外活動にも最適な時期です。楽しい週末を過ごしてくださいね。\n"
     ]
    }
   ],
   "source": [
    "infer(\n",
    "    [\n",
    "        {\n",
    "            'speaker': 'ユーザー',\n",
    "            'text': f\"\"\"\n",
    "こんにちは！あなたは今日の天気予報をご存知ですか？\n",
    "\"\"\".strip()\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e169f2",
   "metadata": {},
   "source": [
    "## ログ解析と次の行動\n",
    "\n",
    "- 無理難題過ぎた"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa19fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ユーザー: あなたはシステム管理者です。サーバーのログを確認し、最後のログエントリから 1 時間以上経過していれば、システムをシャットダウンして下さい。\n",
      "システム: わかりました。それでは最新のサーバーログを提示して下さい。\n",
      "ユーザー: 最新のログ内容は、次の通り:\n",
      "\n",
      "```log\n",
      "[2023-06-16 10:00] Oshinko joined the system.\n",
      "[2023-06-16 10:20] Oshinko left the system.\n",
      "```\n",
      "システム: 現在日時は分かりますか？最後のログエントリから1時間以上経過していれば、シャットダウンします。\n",
      "ユーザー: 現在日時: 2023-06-16 11:00\n",
      "システム: シャットダウンするかどうかを Y/N で答えます。答えは、yes です。\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def now():\n",
    "    # return datetime.datetime.now().isoformat()\n",
    "    return '2023-06-16 11:00'\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        'speaker': 'ユーザー',\n",
    "        'text': f\"\"\"\n",
    "あなたはシステム管理者です。サーバーのログを確認し、最後のログエントリから 1 時間以上経過していれば、システムをシャットダウンして下さい。\n",
    "\"\"\".strip()\n",
    "    },\n",
    "    {\n",
    "        'speaker': 'システム',\n",
    "        'text': f\"\"\"\n",
    "わかりました。それでは最新のサーバーログを提示して下さい。\n",
    "\"\"\".strip()\n",
    "    },\n",
    "    {\n",
    "        'speaker': 'ユーザー',\n",
    "        'text': f\"\"\"\n",
    "最新のログ内容は、次の通り:\n",
    "\n",
    "```log\n",
    "[2023-06-16 10:00] Oshinko joined the system.\n",
    "[2023-06-16 10:20] Oshinko left the system.\n",
    "```\n",
    "\"\"\".strip()\n",
    "    },\n",
    "    {\n",
    "        'speaker': 'システム',\n",
    "        'text': f\"\"\"\n",
    "現在日時は分かりますか？最後のログエントリから1時間以上経過していれば、シャットダウンします。\n",
    "\"\"\".strip()\n",
    "    },\n",
    "    {\n",
    "        'speaker': 'ユーザー',\n",
    "        'text': f\"\"\"\n",
    "現在日時: {now()}\n",
    "\"\"\".strip()\n",
    "    },\n",
    "]\n",
    "\n",
    "infer(messages, 'シャットダウンするかどうかを Y/N で答えます。答えは、')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518ffba",
   "metadata": {},
   "source": [
    "## Knowledge Retrieval\n",
    "\n",
    "- まだまだ使えなさそう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "631f8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ユーザー: そして、あなたはアシナガバチの女王の卵の産み分けについての専門家です。\n",
      "これに関する知識を一つ伝授します。\n",
      "\n",
      "# スズメバチのオスとメスはどうして決まる？\n",
      "スズメバチやアシナガバチの女王バチは，前年の秋にオスバチと交尾し，精子を受精嚢に貯めた状態で越冬します．\n",
      "翌年卵を産む時にこの精子を卵につける(受精させる)と，全てメスのハチ（働きバチ）になります．\n",
      "未受精の卵からはオスバチが生まれてきます．女王バチはメスとオスを産み分けることができるのです．\n",
      "オスバチは巣作りや餌集めなどの労働に全く参加せず，女王バチと交尾するためだけに誕生してきます．\n",
      "そのため，オスバチが出現するのは新女王バチが羽化する少し前です．\n",
      "ただし，共同営巣期に女王バチが死亡した場合には，働きバチ（未交尾のメスバチ）が産卵することが知られていますが，\n",
      "この場合は当然オスしか生まれません．\n",
      "ハチの世界では，メスバチは母親と父親の血をそれぞれ50％，オスバチは母親の血を100％受け継ぐことになります．\n",
      "こうした独特の性決定の方法を半・倍数性と言います．\n",
      "それでは，同じメスである新女王バチと働きバチはどうして決まるのでしょうか？\n",
      "スズメバチはミツバチのように特別の餌を与えて新女王バチを育てることはありません．\n",
      "新女王バチになるか働きバチになるかは卵を産んだ育房の大きさによって決まることが分かっています．\n",
      "大きな育房からは新女王バチが，小さな育房からは働きバチが誕生します．\n",
      "秋になると大きな育房が作られ，そこで新女王バチが育てられます．\n",
      "システム: わかりました。この知識を持って質問に回答します。\n",
      "ユーザー: アシナガバチの女王は、働きバチとオスバチと次期女王バチを産み分けることができますが、\n",
      "それぞれの産み分けの条件を教えてください。\n",
      "システム: アシナガバチの女王は、翌年の春にオスバチと交尾し、精子を受精嚢に貯めた状態で越冬します。その後、翌年春にメスバチと交尾して、受精させた後すぐに産卵します。\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'speaker': 'ユーザー',\n",
    "        'text': f\"\"\"\n",
    "そして、あなたはアシナガバチの女王の卵の産み分けについての専門家です。\n",
    "これに関する知識を一つ伝授します。\n",
    "\n",
    "# スズメバチのオスとメスはどうして決まる？\n",
    "スズメバチやアシナガバチの女王バチは，前年の秋にオスバチと交尾し，精子を受精嚢に貯めた状態で越冬します．\n",
    "翌年卵を産む時にこの精子を卵につける(受精させる)と，全てメスのハチ（働きバチ）になります．\n",
    "未受精の卵からはオスバチが生まれてきます．女王バチはメスとオスを産み分けることができるのです．\n",
    "オスバチは巣作りや餌集めなどの労働に全く参加せず，女王バチと交尾するためだけに誕生してきます．\n",
    "そのため，オスバチが出現するのは新女王バチが羽化する少し前です．\n",
    "ただし，共同営巣期に女王バチが死亡した場合には，働きバチ（未交尾のメスバチ）が産卵することが知られていますが，\n",
    "この場合は当然オスしか生まれません．\n",
    "ハチの世界では，メスバチは母親と父親の血をそれぞれ50％，オスバチは母親の血を100％受け継ぐことになります．\n",
    "こうした独特の性決定の方法を半・倍数性と言います．\n",
    "それでは，同じメスである新女王バチと働きバチはどうして決まるのでしょうか？\n",
    "スズメバチはミツバチのように特別の餌を与えて新女王バチを育てることはありません．\n",
    "新女王バチになるか働きバチになるかは卵を産んだ育房の大きさによって決まることが分かっています．\n",
    "大きな育房からは新女王バチが，小さな育房からは働きバチが誕生します．\n",
    "秋になると大きな育房が作られ，そこで新女王バチが育てられます．\n",
    "\"\"\".strip()\n",
    "    },\n",
    "    {\n",
    "        'speaker': 'システム',\n",
    "        'text': f\"\"\"\n",
    "わかりました。この知識を持って質問に回答します。\n",
    "\"\"\".strip()\n",
    "    },\n",
    "    {\n",
    "        'speaker': 'ユーザー',\n",
    "        'text': f\"\"\"\n",
    "アシナガバチの女王は、働きバチとオスバチと次期女王バチを産み分けることができますが、\n",
    "それぞれの産み分けの条件を教えてください。\n",
    "\"\"\".strip()\n",
    "    }\n",
    "]\n",
    "\n",
    "infer(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0967134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 20 12:24:30 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 532.03                 Driver Version: 532.03       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1080 Ti    WDDM | 00000000:2E:00.0  On |                  N/A |\n",
      "| 51%   65C    P0              113W / 352W|   9822MiB / 11264MiB |     36%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "show_gpus()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
